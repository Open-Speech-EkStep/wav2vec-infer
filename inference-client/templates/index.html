<!doctype html>
<html>

<head>
    <title>Wav2Vec Inference</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <link href="static/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>
    <script src="static/hark.bundle.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.3.0/socket.io.js"
        integrity="sha512-v8ng/uGxkge3d1IJuEo6dJP8JViyvms0cly9pnbfRxT6/31c3dRWxIiwGnMSWwZjHKOuY3EVmijs7k1jz/9bLA=="
        crossorigin="anonymous"></script>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"
        integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
    <script src="static/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <style>
        textarea {
            width: 100%;
            padding: 12px;
            border: 1px solid #ccc;
            border-radius: 4px;
            resize: vertical;
        }

        ::-webkit-input-placeholder {
            /* Chrome/Opera/Safari */
            text-align: center;
        }
        ::-moz-placeholder {
            text-align: center;
        }
        ::-ms-placeholder {
            text-align: center;
        }

        .btn-bs-file {
            position: relative;
            font-size: 16px;
            width: 200px;
        }

        .btn-bs-file input[type="file"] {
            position: absolute;
            top: -9999999;
            filter: alpha(opacity=0);
            opacity: 0;
            width: 0;
            height: 0;
            outline: none;
            cursor: inherit;
        }

        .row {
            padding: 15px;
            margin: 15px;
            border: 1px black solid;
        }

        .btn {
            width: 200px;
        }
    </style>
</head>

<body>
    <center>
        <div class="container">
            <div class="row" style="border: 0px;">
                <div class="col-sm-12">
                    <center>
                        <h4>Wav2Vec Inference Service</h4>
                        <br/>
                        <p>(No Language model present)</p>
                    </center>
                </div>
                <div class="col-sm-12">
                    <div class="row">
                        <div class="col-sm-12">
                            <p>Choose Language:</p>
                            <select class="form-control" id="ddlLanguage" onchange="getval(this);">
                                <option value='en' selected >English</option>
                                <option value='hi'>Hindi</option>
                                <option value='gu'>Gujarati</option>
                                <option value='ta'>Tamil</option>
                                <option value='te'>Telugu</option>
                              </select>
                            <br />
                        </div>
                        <div class="col-sm-12">
                            <img src="static/mic.webp" id="mic_image" onclick="toggle()" height="100" width="100" alt="MIC"/><br />
                        </div>
                        <div class="col-sm-12">
                            <br />
                        </div>
                        <div class="col-sm-12">
                            <textarea id="output" placeholder="Output" readonly></textarea>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </center>
    <script>
        let start = false, socket;
        let current_lang = 'en', selected_lang = 'en';
        let state = "OFF";
        let speechEvents = null;
        let input, processor, context, globalStream, AudioContext;
        let localBuffer = [], isSpeaking = false;

        $(document).ready(function () {
            const socketIO = io();
            socket = socketIO.on('connect', function () {
                start = true;
            });
            socket.on('response', function (data, language) {
                document.getElementById('output').textContent = data;
            });
        });

        function getval(sel){
            current_lang = sel.value;
            if(state === "ON") {
              stopRecording();
            } else {
              socket.emit("end");
            }
        }


        function toggle() {
            if (!start) {
                alert("Try again! socket not connected")
                return;
            }
            let image = document.getElementById("mic_image");
            if (state === "OFF") {
                state = "ON";
                image.src = "static/stop.webp";
                socket.emit("start");
                selected_lang = current_lang;
                startRecording(image);
            } else if (state === "ON") {
                stopRecording()
            }
        }

        function downSampleBuffer(buffer, sampleRate, outSampleRate) {
            if (outSampleRate == sampleRate) {
                return buffer;
            }
            if (outSampleRate > sampleRate) {
                throw "down-sampling rate show be smaller than original sample rate";
            }
            var sampleRateRatio = sampleRate / outSampleRate;
            var newLength = Math.round(buffer.length / sampleRateRatio);
            var result = new Int16Array(newLength);
            var offsetResult = 0;
            var offsetBuffer = 0;
            while (offsetResult < result.length) {
                var nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
                var accum = 0, count = 0;
                for (var i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
                    accum += buffer[i];
                    count++;
                }

                result[offsetResult] = Math.min(1, accum / count) * 0x7FFF;
                offsetResult++;
                offsetBuffer = nextOffsetBuffer;
            }
            return result.buffer;
        }


        function appendBuffer(buffer1, buffer2) {
          const buffer = new ArrayBuffer(buffer1.byteLength + buffer2.byteLength);
          var tmp = new Uint8Array(buffer);
          tmp.set(new Uint8Array(buffer1), 0);
          tmp.set(new Uint8Array(buffer2), buffer1.byteLength);
          return buffer;
        };

        function startRecording(image) {
            let constraints = { audio: true, video: false }
            document.getElementById('output').textContent = "";
            let sendData = false;
            navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                globalStream = stream;
                AudioContext = window.AudioContext || window.webkitAudioContext;
                context = new AudioContext({
                  latencyHint: 'interactive',
                });

                let options = {audioContext: context};
                speechEvents = hark(stream, options);

                speechEvents.on('speaking', function() {
                  isSpeaking = true;
                  console.log('speaking');
                });

                speechEvents.on('stopped_speaking', function() {
                  console.log('stopped_speaking');
                  isSpeaking = false;
                });

                processor = context.createScriptProcessor(16384, 1, 1);
                input = context.createMediaStreamSource(stream);

                processor.connect(context.destination);
                context.resume();
                input.connect(processor);
                let sentOnce = true;
                processor.onaudioprocess = function (e) {
                  var data_44100 = e.inputBuffer.getChannelData(0);
                  var data_16000 = downSampleBuffer(data_44100, 44100, 16000);
                  if(isSpeaking){
                    sentOnce = false;

                    if(localBuffer.length > 0){
                        data_16000 = appendBuffer(localBuffer[localBuffer.length-1], data_16000)
                    }
                    console.log("emitted", data_16000);
                    socket.emit('mic_data', data_16000, current_lang,true);
                    localBuffer = [];
                  } else {
                    if(!sentOnce){
                        sentOnce= true;
                        socket.emit('mic_data', data_16000, current_lang,false);
                        console.log("emitted last");
                    } else {
                        /*let maxLength = 3;
                        let buffLength = localBuffer.length;
                        if(buffLength > maxLength){
                            let temp = [];
                            for(let i=maxLength;i>0;i++){
                                temp.push(localBuffer[buffLength - maxLength]);
                            }
                            localBuffer = temp;
                        } else {
                            localBuffer.push(data_16000)
                        }*/
                        localBuffer.push(data_16000)
                    }
                  }
                };
            }).catch(function (err) {
                image.src = "static/mic.webp";
                state = "OFF";
            });
        }

        function stopIt(){
            let track = globalStream.getTracks()[0];
            track.stop();

            input.disconnect(processor);
            processor.disconnect(context.destination);
            context.close().then(function () {
                input = null;
                processor = null;
                context = null;
                AudioContext = null;
            });
        }

        function endProcess() {
            socket.emit("end");
            stopIt();
            speechEvents.stop();
        }

        function stopRecording(){
            let image = document.getElementById("mic_image");
            state = "OFF";
            image.src = "static/mic.webp";
            endProcess();
        }
    </script>
</body>

</html>
